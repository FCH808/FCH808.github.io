{
 "metadata": {
  "name": "",
  "signature": "sha256:c9471d985ebc1abcc74a97ec673e507224296895f1cd7581cace7499a8c725ea"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load scripts/class_vis.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "#from udacityplots import *\n",
      "import matplotlib \n",
      "matplotlib.use('agg')\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import pylab as pl\n",
      "import numpy as np\n",
      "\n",
      "#import numpy as np\n",
      "#import matplotlib.pyplot as plt\n",
      "#plt.ioff()\n",
      "\n",
      "def prettyPicture(clf, X_test, y_test):\n",
      "    x_min = 0.0; x_max = 1.0\n",
      "    y_min = 0.0; y_max = 1.0\n",
      "\n",
      "    # Plot the decision boundary. For that, we will assign a color to each\n",
      "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
      "    h = .01  # step size in the mesh\n",
      "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
      "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "\n",
      "    # Put the result into a color plot\n",
      "    Z = Z.reshape(xx.shape)\n",
      "    plt.xlim(xx.min(), xx.max())\n",
      "    plt.ylim(yy.min(), yy.max())\n",
      "\n",
      "    plt.pcolormesh(xx, yy, Z, cmap=pl.cm.seismic)\n",
      "\n",
      "    # Plot also the test points\n",
      "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
      "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
      "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
      "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
      "\n",
      "    plt.scatter(grade_sig, bumpy_sig, color = \"b\", label=\"fast\")\n",
      "    plt.scatter(grade_bkg, bumpy_bkg, color = \"r\", label=\"slow\")\n",
      "    plt.legend()\n",
      "    plt.xlabel(\"bumpiness\")\n",
      "    plt.ylabel(\"grade\")\n",
      "    plt.show()\n",
      "    #plt.savefig(\"test.png\")\n",
      "    \n",
      "import base64\n",
      "import json\n",
      "import subprocess\n",
      "\n",
      "def output_image(name, format, bytes):\n",
      "    image_start = \"BEGIN_IMAGE_f9825uweof8jw9fj4r8\"\n",
      "    image_end = \"END_IMAGE_0238jfw08fjsiufhw8frs\"\n",
      "    data = {}\n",
      "    data['name'] = name\n",
      "    data['format'] = format\n",
      "    data['bytes'] = base64.encodestring(bytes)\n",
      "    print image_start+json.dumps(data)+image_end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load scripts/prep_terrain_data.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "import random\n",
      "\n",
      "\n",
      "def makeTerrainData(n_points=1000):\n",
      "###############################################################################\n",
      "### make the toy dataset\n",
      "    random.seed(42)\n",
      "    grade = [random.random() for ii in range(0,n_points)]\n",
      "    bumpy = [random.random() for ii in range(0,n_points)]\n",
      "    error = [random.random() for ii in range(0,n_points)]\n",
      "    y = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]\n",
      "    for ii in range(0, len(y)):\n",
      "        if grade[ii]>0.8 or bumpy[ii]>0.8:\n",
      "            y[ii] = 1.0\n",
      "\n",
      "### split into train/test sets\n",
      "    X = [[gg, ss] for gg, ss in zip(grade, bumpy)]\n",
      "    split = int(0.75*n_points)\n",
      "    X_train = X[0:split]\n",
      "    X_test  = X[split:]\n",
      "    y_train = y[0:split]\n",
      "    y_test  = y[split:]\n",
      "\n",
      "    grade_sig = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
      "    bumpy_sig = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
      "    grade_bkg = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
      "    bumpy_bkg = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
      "\n",
      "#    training_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
      "#            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
      "\n",
      "\n",
      "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
      "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
      "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
      "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
      "\n",
      "    test_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
      "            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
      "\n",
      "    return X_train, y_train, X_test, y_test\n",
      "#    return training_data, test_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "#!/usr/bin/python\n",
      "\n",
      "\"\"\" lecture and example code for decision tree unit \"\"\"\n",
      "\n",
      "import sys\n",
      "#from class_vis import prettyPicture, output_image\n",
      "#from prep_terrain_data import makeTerrainData\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "# from classifyDT import classify\n",
      "\n",
      "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
      "\n",
      "\n",
      "\n",
      "def classify(features_train, labels_train, min_split=2):\n",
      "    \n",
      "    from sklearn.tree import DecisionTreeClassifier\n",
      "    \n",
      "    clf = DecisionTreeClassifier(min_samples_split=min_split)\n",
      "    \n",
      "    clf.fit(features_train, labels_train)\n",
      "    return clf\n",
      "\n",
      "### the classify() function in classifyDT is where the magic\n",
      "### happens--it's your job to fill this in!\n",
      "clf = classify(features_train, labels_train)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#### grader code, do not modify below this line\n",
      "\n",
      "prettyPicture(clf, features_test, labels_test)\n",
      "\n",
      "#output_image(\"test.png\", \"png\", open(\"test.png\", \"rb\").read())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4whxDwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x3aec978>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = clf.predict(features_test)\n",
      "\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "acc = accuracy_score(pred, labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.908\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf50 = classify(features_train, labels_train, min_split=50)\n",
      "pred50 = clf50.predict(features_test)\n",
      "acc50 = accuracy_score(pred50, labels_test)\n",
      "print acc50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.912\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats\n",
      "print scipy.stats.entropy([2,1], base=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.918295834054\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Information gain: \", 1-(.9184*.75 + .25 * 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Information gain:  0.3112\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print scipy.stats.entropy([2, 2], base=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Information gain: \", 1-(.5*1 + .5*1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Information gain:  0.0\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-math.log(.66666,2) * 2/3 - math.log(.33333, 2) * 1/3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "0.9183102610770337"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load ../ud120-projects/decision_tree/dt_author_id.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%writefile ../ud120-projects/decision_tree/dt_author_id.py\n",
      "#!/usr/bin/python\n",
      "\n",
      "\"\"\" \n",
      "    this is the code to accompany the Lesson 3 (decision tree) mini-project\n",
      "\n",
      "    use an DT to identify emails from the Enron corpus by their authors\n",
      "    \n",
      "    Sara has label 0\n",
      "    Chris has label 1\n",
      "\n",
      "\"\"\"\n",
      "    \n",
      "import sys\n",
      "from time import time\n",
      "sys.path.append(\"../ud120-projects/tools/\")\n",
      "from email_preprocess import preprocess\n",
      "\n",
      "\n",
      "### features_train and features_test are the features for the training\n",
      "### and testing datasets, respectively\n",
      "### labels_train and labels_test are the corresponding item labels\n",
      "features_train, features_test, labels_train, labels_test = preprocess()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier \n",
      "\n",
      "clf = DecisionTreeClassifier(min_samples_split=40)\n",
      "\n",
      "clf.fit(features_train, labels_train)\n",
      "\n",
      "pred = clf.predict(features_test)\n",
      "\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "acc = accuracy_score(pred, labels_test)\n",
      "\n",
      "print \"Accuracy:, \", acc\n",
      "\n",
      "#########################################################\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no. of Chris training emails: 7936\n",
        "no. of Sara training emails: 7884\n",
        "Accuracy:, "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.978953356086\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "(15820L, 3785L)"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load ../ud120-projects/tools/email_preprocess.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %%writefile ../ud120-projects/tools/email_preprocess.py\n",
      "#!/usr/bin/python\n",
      "\n",
      "import pickle\n",
      "import numpy\n",
      "\n",
      "from sklearn import cross_validation\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_selection import SelectPercentile, f_classif\n",
      "\n",
      "\n",
      "\n",
      "def preprocess(words_file = \"../ud120-projects/tools/word_data.pkl\", authors_file=\"../ud120-projects/tools/email_authors.pkl\"):\n",
      "    \"\"\" \n",
      "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
      "        and the corresponding authors (by default email_authors.pkl) and performs\n",
      "        a number of preprocessing steps:\n",
      "            -- splits into training/testing sets (10% testing)\n",
      "            -- vectorizes into tfidf matrix\n",
      "            -- selects/keeps most helpful features\n",
      "\n",
      "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
      "\n",
      "        4 objects are returned:\n",
      "            -- training/testing features\n",
      "            -- training/testing labels\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    ### the words (features) and authors (labels), already largely preprocessed\n",
      "    ### this preprocessing will be repeated in the text learning mini-project\n",
      "    \n",
      "    word_data = pickle.load( open(words_file, \"r\"))\n",
      "    authors = pickle.load( open(authors_file, \"r\") )\n",
      "\n",
      "    ### test_size is the percentage of events assigned to the test set (remainder go into training)\n",
      "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
      "\n",
      "\n",
      "\n",
      "    ### text vectorization--go from strings to lists of numbers\n",
      "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
      "                                 stop_words='english')\n",
      "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
      "    features_test_transformed  = vectorizer.transform(features_test)\n",
      "\n",
      "\n",
      "\n",
      "    ### feature selection, because text is super high dimensional and \n",
      "    ### can be really computationally chewy as a result\n",
      "    selector = SelectPercentile(f_classif, percentile=1)\n",
      "    selector.fit(features_train_transformed, labels_train)\n",
      "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
      "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
      "\n",
      "    ### info on the data\n",
      "    print \"no. of Chris training emails:\", sum(labels_train)\n",
      "    print \"no. of Sara training emails:\", len(labels_train)-sum(labels_train)\n",
      "\n",
      "\n",
      "    return features_train_transformed, features_test_transformed, labels_train, labels_test\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting ../ud120-projects/tools/email_preprocess.py\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load ../ud120-projects/decision_tree/dt_author_id.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "\"\"\" \n",
      "    this is the code to accompany the Lesson 3 (decision tree) mini-project\n",
      "\n",
      "    use an DT to identify emails from the Enron corpus by their authors\n",
      "    \n",
      "    Sara has label 0\n",
      "    Chris has label 1\n",
      "\n",
      "\"\"\"\n",
      "    \n",
      "import sys\n",
      "from time import time\n",
      "sys.path.append(\"../ud120-projects/tools/\")\n",
      "from email_preprocess import preprocess\n",
      "\n",
      "\n",
      "### features_train and features_test are the features for the training\n",
      "### and testing datasets, respectively\n",
      "### labels_train and labels_test are the corresponding item labels\n",
      "features_train, features_test, labels_train, labels_test = preprocess()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#########################################################\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier \n",
      "\n",
      "clf = DecisionTreeClassifier(min_samples_split=40)\n",
      "\n",
      "clf.fit(features_train, labels_train)\n",
      "\n",
      "pred = clf.predict(features_test)\n",
      "\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "acc = accuracy_score(pred, labels_test)\n",
      "\n",
      "print \"Accuracy:, \", acc\n",
      "\n",
      "#########################################################\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no. of Chris training emails: 7936\n",
        "no. of Sara training emails: 7884\n",
        "Accuracy:, "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.967007963595\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(15820L, 379L)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}