{
 "metadata": {
  "name": "",
  "signature": "sha256:a8847b4141abc12414a6e0c8abf415a1a71895e25a26cb3e16123fb9bc644da9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load scripts/poi_flag_email.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#writefile scripts/poi_flag_email.py\n",
      "#!/usr/bin/python\n",
      "\n",
      "###\n",
      "### in poiFlagEmail() below, write code that returns a boolean\n",
      "### indicating if a given email is from a POI\n",
      "###\n",
      "\n",
      "import sys\n",
      "import reader\n",
      "import poi_emails\n",
      "\n",
      "def getToFromStrings(f):\n",
      "    f.seek(0)\n",
      "    to_string, from_string, cc_string   = reader.getAddresses(f)\n",
      "    to_emails   = reader.parseAddresses( to_string )\n",
      "    from_emails = reader.parseAddresses( from_string )\n",
      "    cc_emails   = reader.parseAddresses( cc_string )\n",
      "\n",
      "    return to_emails, from_emails, cc_emails\n",
      "\n",
      "\n",
      "### POI flag an email\n",
      "\n",
      "def poiFlagEmail(f):\n",
      "    \"\"\" given an email file f,\n",
      "        return a trio of booleans for whether that email is\n",
      "        to, from, or cc'ing a poi \"\"\"\n",
      "\n",
      "    to_emails, from_emails, cc_emails = getToFromStrings(f)\n",
      "\n",
      "    ### list of email addresses of all the POIs\n",
      "    poi_email_list = poi_emails.poiEmails()\n",
      "\n",
      "    to_poi = False\n",
      "    from_poi = False\n",
      "    cc_poi   = False\n",
      "\n",
      "    ### to_poi and cc_poi are related functions, which flag whether\n",
      "    ### the email under inspection is addressed to a POI, or if a POI is in cc\n",
      "    ### you don't have to change this code at all\n",
      "\n",
      "    ### there can be many \"to\" emails, but only one \"from\", so the\n",
      "    ### \"to\" processing needs to be a little more complicated\n",
      "    if to_emails:\n",
      "        ctr = 0\n",
      "        while not to_poi and ctr < len(to_emails):\n",
      "            if to_emails[ctr] in poi_email_list:\n",
      "                to_poi = True\n",
      "            ctr += 1\n",
      "    if cc_emails:\n",
      "        ctr = 0\n",
      "        while not to_poi and ctr < len(cc_emails):\n",
      "            if cc_emails[ctr] in poi_email_list:\n",
      "                cc_poi = True\n",
      "            ctr += 1\n",
      "\n",
      "\n",
      "    #################################\n",
      "    ######## your code below ########\n",
      "    ### set from_poi to True if #####\n",
      "    ### the email is from a POI #####\n",
      "    #################################\n",
      "\n",
      "    if from_emails:\n",
      "        ctr = 0\n",
      "        while not from_poi and ctr < len(from_emails):\n",
      "            if from_emails[ctr] in poi_email_list:\n",
      "                from_poi = True\n",
      "            ctr += 1    \n",
      "    \n",
      "    \n",
      "\n",
      "    #################################\n",
      "    return to_poi, from_poi, cc_poi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting scripts/poi_flag_email.py\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "#help(TfidfVectorizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load ../ud120-projects/feature_selection/find_signature.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "import pickle\n",
      "import numpy\n",
      "numpy.random.seed(42)\n",
      "\n",
      "\n",
      "### the words (features) and authors (labels), already largely processed\n",
      "words_file = \"../ud120-projects/text_learning/your_word_data.pkl\" ### like the file you made in the last mini-project \n",
      "authors_file = \"../ud120-projects/text_learning/your_email_authors.pkl\"  ### this too\n",
      "word_data = pickle.load( open(words_file, \"r\"))\n",
      "authors = pickle.load( open(authors_file, \"r\") )\n",
      "\n",
      "\n",
      "\n",
      "### test_size is the percentage of events assigned to the test set (remainder go into training)\n",
      "from sklearn import cross_validation\n",
      "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
      "\n",
      "\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
      "                             stop_words='english')\n",
      "features_train = vectorizer.fit_transform(features_train).toarray()\n",
      "features_test  = vectorizer.transform(features_test).toarray()\n",
      "\n",
      "\n",
      "### a classic way to overfit is to use a small number\n",
      "### of data points and a large number of features\n",
      "### train on only 150 events to put ourselves in this regime\n",
      "features_train = features_train[:150]\n",
      "labels_train   = labels_train[:150]\n",
      "\n",
      "\n",
      "\n",
      "### your code goes here\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "model = DecisionTreeClassifier()\n",
      "\n",
      "model.fit(features_train, labels_train)\n",
      "\n",
      "pred_train = model.predict(features_train)\n",
      "pred_test = model.predict(features_test)\n",
      "\n",
      "overfit_acc_train = accuracy_score(labels_train, pred_train)\n",
      "overfit_acc_test = accuracy_score(labels_test, pred_test)\n",
      "print len(labels_train)\n",
      "print overfit_acc_test\n",
      "print overfit_acc_train\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "150\n",
        "0.816837315131\n",
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print [x for x in sorted(model.feature_importances_, reverse=True) if x > 0.2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.36363636363636365]\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print numpy.argmax(model.feature_importances_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21323\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.feature_importances_.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "0.36363636363636365"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " [(feature,key) for key,feature in enumerate(model.feature_importances_) if feature >= 0.2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "[(0.36363636363636365, 21323)]"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.feature_importances_.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "37861"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer.get_feature_names()[33614]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "u'sshacklsims1rcsntxswbellnet'"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer.get_feature_names()[14343]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "u'cgermannsf'"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer.get_feature_names()[21323]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "u'houectect'"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}